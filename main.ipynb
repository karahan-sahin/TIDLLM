{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: opencv-python in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (4.9.0.80)\n",
      "Collecting vector-quantize-pytorch (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for vector-quantize-pytorch from https://files.pythonhosted.org/packages/25/ed/71b701d355c3c2c3454fa002efd1fb0270a083080777038ec2c95a63523f/vector_quantize_pytorch-1.14.6-py3-none-any.whl.metadata\n",
      "  Downloading vector_quantize_pytorch-1.14.6-py3-none-any.whl.metadata (716 bytes)\n",
      "Requirement already satisfied: filelock in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.4.99)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from opencv-python->-r requirements.txt (line 2)) (1.24.3)\n",
      "Collecting einops>=0.7.0 (from vector-quantize-pytorch->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for einops>=0.7.0 from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting einx[torch]>=0.1.3 (from vector-quantize-pytorch->-r requirements.txt (line 4))\n",
      "  Downloading einx-0.1.3.tar.gz (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m748.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting frozendict (from einx[torch]>=0.1.3->vector-quantize-pytorch->-r requirements.txt (line 4))\n",
      "  Downloading frozendict-2.4.1.tar.gz (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.2/315.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/kara-nlp/anaconda3/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Downloading vector_quantize_pytorch-1.14.6-py3-none-any.whl (28 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: einx, frozendict\n",
      "  Building wheel for einx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for einx: filename=einx-0.1.3-py3-none-any.whl size=80073 sha256=f6abbe8307af804b8d9af4ce38b89a9f1f3fbd597144cbe07c478b5cd25f91bc\n",
      "  Stored in directory: /home/kara-nlp/.cache/pip/wheels/57/be/70/7b84c8e04d0eeab2064a315b2cab6de6838ff6372f489bd88d\n",
      "  Building wheel for frozendict (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for frozendict: filename=frozendict-2.4.1-cp311-cp311-linux_x86_64.whl size=15499 sha256=4f3fe8d4489f8c3135b94213c97e332a1619298eb8a86f42edc1db0831a0e4a7\n",
      "  Stored in directory: /home/kara-nlp/.cache/pip/wheels/02/6e/a0/b90b693ddaaf2bde1efb47df2576175a1983aef24936f71694\n",
      "Successfully built einx frozendict\n",
      "Installing collected packages: frozendict, einops, einx, vector-quantize-pytorch\n",
      "Successfully installed einops-0.7.0 einx-0.1.3 frozendict-2.4.1 vector-quantize-pytorch-1.14.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from vector_quantize_pytorch import VectorQuantize, ResidualVQ\n",
    "\n",
    "from lib.config import *\n",
    "from lib.encoder.ffn import FFNEncoder, FFNDecoder\n",
    "from lib.encoder.vqvae import VQVAE\n",
    "from lib.train.run_autoencoder_training import AutoencoderTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pose Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.pose import get_pose_estimation\n",
    "\n",
    "SAMPLE = 'dataset/corpus/ABARTMAK_0.mp4'\n",
    "\n",
    "SAMPLE_POSE = get_pose_estimation(SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_pose_array(SAMPLE_POSE):\n",
    "    \"\"\"Converts the pose data into a numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    POSE_RAW = pd.DataFrame(SAMPLE_POSE['pose'])\n",
    "    RIGHT_HAND_RAW = pd.DataFrame(SAMPLE_POSE['right'])\n",
    "    LEFT_HAND_RAW = pd.DataFrame(SAMPLE_POSE['left'])\n",
    "\n",
    "    POSE_DF = {}\n",
    "\n",
    "    for col in POSE_RAW.columns:\n",
    "        POSE_DF[ 'POSE_' + col + '_X'] = POSE_RAW[col].apply(lambda x: x[0])\n",
    "        POSE_DF[ 'POSE_' + col + '_Y'] = POSE_RAW[col].apply(lambda x: x[1])\n",
    "        POSE_DF[ 'POSE_' + col + '_Z'] = POSE_RAW[col].apply(lambda x: x[2])\n",
    "        # POSE_DF[col + '_viz'] = POSE_RAW[col].apply(lambda x: x[3])\n",
    "\n",
    "    for col in RIGHT_HAND_RAW.columns:\n",
    "        POSE_DF[ 'RIGHT_' + col + '_X' ] = RIGHT_HAND_RAW[col].apply(lambda x: x[0])\n",
    "        POSE_DF[ 'RIGHT_' + col + '_Y' ] = RIGHT_HAND_RAW[col].apply(lambda x: x[1])\n",
    "        POSE_DF[ 'RIGHT_' + col + '_Z' ] = RIGHT_HAND_RAW[col].apply(lambda x: x[2])\n",
    "        # POSE_DF['RIGHT_' + col + '_viz'] = RIGHT_HAND_RAW[col].apply(lambda x: x[3])\n",
    "\n",
    "    for col in LEFT_HAND_RAW.columns:\n",
    "        POSE_DF[ 'LEFT_' + col + '_X' ] = LEFT_HAND_RAW[col].apply(lambda x: x[0])\n",
    "        POSE_DF[ 'LEFT_' + col + '_Y' ] = LEFT_HAND_RAW[col].apply(lambda x: x[1])\n",
    "        POSE_DF[ 'LEFT_' + col + '_Z' ] = LEFT_HAND_RAW[col].apply(lambda x: x[2])\n",
    "        # POSE_DF['LEFT_' + col + '_viz'] = LEFT_HAND_RAW[col].apply(lambda x: x[3])\n",
    "\n",
    "    POSE_DF = pd.DataFrame(POSE_DF)\n",
    "\n",
    "    return POSE_DF.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    ARRAY_PATH = 'dataset/pose/'\n",
    "    for datapath in tqdm(glob.glob('dataset/corpus/*.mp4')):\n",
    "        print(datapath)\n",
    "        pose = get_pose_estimation(datapath)\n",
    "        pose_array = get_pose_array(pose)\n",
    "        print(pose_array.shape, datapath)\n",
    "        dname = datapath.split('/')[-1].replace('.mp4', '.npy')\n",
    "        with open(ARRAY_PATH+'/'+dname, 'wb') as f:\n",
    "            np.save(f, pose_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Graph Autoencoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'dataset/pose/'\n",
    "data = glob.glob(DATA_PATH + '*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2716/2716 [00:02<00:00, 908.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from lib.data.dataset import PoseDataset\n",
    "\n",
    "train_dataset = PoseDataset(X_train)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=GLOBAL_CONFIG.BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 679/679 [00:00<00:00, 993.78it/s] \n"
     ]
    }
   ],
   "source": [
    "val_dataset = PoseDataset(X_val)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=GLOBAL_CONFIG.BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kara-nlp/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "MODEL_ENCODER = FFNEncoder(\n",
    "    input_dim=GLOBAL_CONFIG.MODEL_ENCODER_INPUT_DIM,\n",
    "    hidden_dim=GLOBAL_CONFIG.MODEL_ENCODER_HIDDEN_DIM,\n",
    "    output_dim=GLOBAL_CONFIG.MODEL_ENCODER_OUTPUT_DIM,\n",
    ")\n",
    "\n",
    "MODEL_DECODER = FFNDecoder(\n",
    "    input_dim=GLOBAL_CONFIG.MODEL_DECODER_INPUT_DIM,\n",
    "    hidden_dim=GLOBAL_CONFIG.MODEL_DECODER_HIDDEN_DIM,\n",
    "    output_dim=GLOBAL_CONFIG.MODEL_ENCODER_INPUT_DIM,\n",
    ")\n",
    "\n",
    "MODEL_QUANT = ResidualVQ(\n",
    "    dim = GLOBAL_CONFIG.MODEL_VQ_EMBED_DIM,\n",
    "    stochastic_sample_codes = True,\n",
    "    num_quantizers=1,      # specify number of quantizers\n",
    "    codebook_size=GLOBAL_CONFIG.MODEL_VQ_NUM_EMBS,    # codebook size           # the weight on the commitment loss\n",
    "    kmeans_init=True,   # set to True\n",
    "    kmeans_iters=100     # number of kmeans iterations to calculate the centroids for the codebook on init\n",
    ")\n",
    "\n",
    "MODEL_VQVAE = VQVAE(\n",
    "    encoder=MODEL_ENCODER,\n",
    "    decoder=MODEL_DECODER,\n",
    "    vq=MODEL_QUANT,\n",
    ")\n",
    "\n",
    "trainer = AutoencoderTrainer(\n",
    "    model=MODEL_VQVAE,\n",
    "    learning_rate=GLOBAL_CONFIG.LEARNING_RATE,\n",
    "    train_dataloader=train_dataloader, \n",
    "    val_dataloader=val_dataloader,\n",
    "    num_epochs=GLOBAL_CONFIG.NUM_EPOCHS,\n",
    "    device='cpu',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4c14eb2b87490782f6df0acea1d02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4728 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "MODEL_VQVAE.eval()\n",
    "\n",
    "dfs = []\n",
    "for train_sample in tqdm(train_dataloader):\n",
    "    with torch.no_grad():\n",
    "        quantized, indices, commitment_loss = MODEL_VQVAE(train_sample['array'].float())\n",
    "        dfs.append(pd.DataFrame({\n",
    "            'videos': train_sample['token'],\n",
    "            'labels': indices.detach().cpu().numpy().reshape(-1)\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5064</th>\n",
       "      <td>1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6259</th>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8327</th>\n",
       "      <td>1626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>1547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9784</th>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8025</th>\n",
       "      <td>1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9019</th>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9781</th>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8087</th>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8616</th>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9584</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "labels       \n",
       "1344     1716\n",
       "5064     1702\n",
       "497      1675\n",
       "6259     1639\n",
       "8327     1626\n",
       "8766     1547\n",
       "4175     1537\n",
       "7469     1489\n",
       "9784     1414\n",
       "4077     1381\n",
       "4888     1378\n",
       "3752     1378\n",
       "9054     1374\n",
       "8025     1365\n",
       "4180     1273\n",
       "6786     1269\n",
       "5315     1255\n",
       "5303     1226\n",
       "4970     1212\n",
       "9019     1194\n",
       "5827     1173\n",
       "5240     1117\n",
       "1549     1117\n",
       "9427     1074\n",
       "900      1074\n",
       "5395     1073\n",
       "5249     1054\n",
       "5589     1000\n",
       "9781      996\n",
       "242       939\n",
       "5022      888\n",
       "792       886\n",
       "8087      850\n",
       "4775      834\n",
       "8616      818\n",
       "3310      773\n",
       "2900      751\n",
       "5949      747\n",
       "8211      691\n",
       "6471      685\n",
       "7802      549\n",
       "7144      528\n",
       "175       501\n",
       "2763      377\n",
       "4708      341\n",
       "2825      315\n",
       "8028      278\n",
       "7468      157\n",
       "9584      141\n",
       "1843       64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.labels.value_counts()).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videos</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KUAFO╠êR_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YUMUS╠ğAK _0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KRIZ_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ONARMAK_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BUHAR_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAG╠åMAK_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAY_1.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MANZARA_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>YAYLA_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAS╠ğARI_0.npy</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              videos  labels\n",
       "6     KUAFO╠êR_0.npy    7468\n",
       "10  YUMUS╠ğAK _0.npy    7468\n",
       "8         KRIZ_0.npy    7468\n",
       "27     ONARMAK_0.npy    7468\n",
       "18       BUHAR_0.npy    7468\n",
       "3     YAG╠åMAK_0.npy    7468\n",
       "5          VAY_1.npy    7468\n",
       "1      MANZARA_0.npy    7468\n",
       "23       YAYLA_0.npy    7468\n",
       "0     BAS╠ğARI_0.npy    7468"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['labels'] == 7468].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
